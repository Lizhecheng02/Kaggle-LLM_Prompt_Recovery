{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-12T05:41:26.511070Z","iopub.status.busy":"2024-03-12T05:41:26.509677Z","iopub.status.idle":"2024-03-12T05:41:26.933686Z","shell.execute_reply":"2024-03-12T05:41:26.931429Z","shell.execute_reply.started":"2024-03-12T05:41:26.511001Z"},"trusted":true},"outputs":[],"source":["import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import time\n","import random\n","from openai import OpenAI\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:26.935823Z","iopub.status.busy":"2024-03-12T05:41:26.935391Z","iopub.status.idle":"2024-03-12T05:41:39.265037Z","shell.execute_reply":"2024-03-12T05:41:39.263370Z","shell.execute_reply.started":"2024-03-12T05:41:26.935794Z"},"trusted":true},"outputs":[],"source":["!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:39.267834Z","iopub.status.busy":"2024-03-12T05:41:39.267441Z","iopub.status.idle":"2024-03-12T05:41:39.898695Z","shell.execute_reply":"2024-03-12T05:41:39.897701Z","shell.execute_reply.started":"2024-03-12T05:41:39.267799Z"},"trusted":true},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = \"\"\n","\n","\n","def get_response(msg):\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": msg\n","        }\n","    ]\n","\n","    temperature = random.uniform(0.7, 1.0)\n","    client = OpenAI()\n","    response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo-0125\",\n","        messages=messages,\n","        temperature=temperature\n","    )\n","\n","    output = response.choices[0].message.content\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:39.901453Z","iopub.status.busy":"2024-03-12T05:41:39.900344Z","iopub.status.idle":"2024-03-12T05:41:40.087584Z","shell.execute_reply":"2024-03-12T05:41:40.086439Z","shell.execute_reply.started":"2024-03-12T05:41:39.901416Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('datasets/lb_related_5k.csv')\n","# df = df[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:40.091476Z","iopub.status.busy":"2024-03-12T05:41:40.090731Z","iopub.status.idle":"2024-03-12T05:41:40.107674Z","shell.execute_reply":"2024-03-12T05:41:40.106582Z","shell.execute_reply.started":"2024-03-12T05:41:40.091433Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:40.109512Z","iopub.status.busy":"2024-03-12T05:41:40.108974Z","iopub.status.idle":"2024-03-12T05:41:40.113955Z","shell.execute_reply":"2024-03-12T05:41:40.113165Z","shell.execute_reply.started":"2024-03-12T05:41:40.109478Z"},"trusted":true},"outputs":[],"source":["# def g(df, col):\n","#     return df.groupby(col).apply(lambda x: x.sample(1)).reset_index(drop=True)\n","# result = g(df.copy(), 'rewrite_prompt')\n","result = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:40.115756Z","iopub.status.busy":"2024-03-12T05:41:40.115213Z","iopub.status.idle":"2024-03-12T05:41:40.126893Z","shell.execute_reply":"2024-03-12T05:41:40.125660Z","shell.execute_reply.started":"2024-03-12T05:41:40.115726Z"},"trusted":true},"outputs":[],"source":["def formatting_prompts_func(examples):\n","    inst = \"\"\"\n","You'll be given an original text and a rewritten text generated by an LLM. The prompt that guided the LLM's changes will be given as well. \n","Suppose you don't know the original prompt, your task is to analyze the differences between an original text and a rewritten version generated by an LLM and try to infer it based on the differences you see. \n","Provide a detailed explanation of how you arrived at your inference step by step.\n","\n","**Original Text**:\n","{}\n","\n","**Prompt**:\n","{}\n","\n","**Rewritten Text**\n","{}\n","\n","You should response in the following format:\n","**Inferred Promp**: ...\n","\n","**Chain of Thoughts**: ...\n","\"\"\"\n","    return inst.format(examples['original_text'], examples['rewrite_prompt'], examples['rewritten_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:40.129445Z","iopub.status.busy":"2024-03-12T05:41:40.128348Z","iopub.status.idle":"2024-03-12T05:41:50.266493Z","shell.execute_reply":"2024-03-12T05:41:50.265376Z","shell.execute_reply.started":"2024-03-12T05:41:40.129404Z"},"trusted":true},"outputs":[],"source":["cot = []\n","for idx, row in tqdm(result.iterrows(), total=len(result)):\n","    # 输入提示\n","    try:\n","        prompt_parts = formatting_prompts_func(row)\n","        # 输出回答\n","        while True:\n","            try:\n","                response = get_response(prompt_parts)\n","                break\n","            except Exception as e:\n","                print(e)\n","                time.sleep(1)\n","\n","        cot.append(response)\n","#         print(response)\n","    except:\n","        cot.append(\"\")\n","\n","result['cot'] = cot\n","result.to_csv('./datasets_with_cot.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T05:41:50.268291Z","iopub.status.busy":"2024-03-12T05:41:50.267929Z","iopub.status.idle":"2024-03-12T05:41:50.276431Z","shell.execute_reply":"2024-03-12T05:41:50.275337Z","shell.execute_reply.started":"2024-03-12T05:41:50.268249Z"},"trusted":true},"outputs":[],"source":["# result['cot'].values"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4538357,"sourceId":7790371,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05878d51",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-03-11T15:51:24.446300Z",
     "iopub.status.busy": "2024-03-11T15:51:24.445263Z",
     "iopub.status.idle": "2024-03-11T15:52:47.151183Z",
     "shell.execute_reply": "2024-03-11T15:52:47.150026Z"
    },
    "papermill": {
     "duration": 82.717777,
     "end_time": "2024-03-11T15:52:47.153819",
     "exception": false,
     "start_time": "2024-03-11T15:51:24.436042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed\n",
    "!pip install --no-index /kaggle/input/download-pacakages-for-llm/unsloth/peft-0.9.0-py3-none-any.whl --find-links=/kaggle/input/download-pacakages-for-llm/unsloth\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/bitsandbytes-0.42.0-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/accelerate-0.27.2-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/download-pacakages-for-llm/unsloth/transformers-4.38.2-py3-none-any.whl --find-links=/kaggle/input/download-pacakages-for-llm/unsloth\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/optimum-1.17.1-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6e854",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-03-11T15:52:47.173984Z",
     "iopub.status.busy": "2024-03-11T15:52:47.173665Z",
     "iopub.status.idle": "2024-03-11T15:52:58.494041Z",
     "shell.execute_reply": "2024-03-11T15:52:58.493182Z"
    },
    "papermill": {
     "duration": 11.333121,
     "end_time": "2024-03-11T15:52:58.496284",
     "exception": false,
     "start_time": "2024-03-11T15:52:47.163163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from accelerate.utils import BnbQuantizationConfig\n",
    "from accelerate import Accelerator\n",
    "import transformers\n",
    "import optimum\n",
    "import bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4953f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:52:58.516508Z",
     "iopub.status.busy": "2024-03-11T15:52:58.516094Z",
     "iopub.status.idle": "2024-03-11T15:52:58.520329Z",
     "shell.execute_reply": "2024-03-11T15:52:58.519516Z"
    },
    "papermill": {
     "duration": 0.01606,
     "end_time": "2024-03-11T15:52:58.522225",
     "exception": false,
     "start_time": "2024-03-11T15:52:58.506165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01037a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:52:58.540448Z",
     "iopub.status.busy": "2024-03-11T15:52:58.540192Z",
     "iopub.status.idle": "2024-03-11T15:55:17.855549Z",
     "shell.execute_reply": "2024-03-11T15:55:17.854756Z"
    },
    "papermill": {
     "duration": 139.32673,
     "end_time": "2024-03-11T15:55:17.857800",
     "exception": false,
     "start_time": "2024-03-11T15:52:58.531070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig, StoppingCriteria\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Comment/Uncomment and use as per wish\n",
    "\n",
    "MODEL_PATH = \"/kaggle/input/gemma-7b-instruction\"\n",
    "# MODEL_PATH = \"/kaggle/input/gemma/transformers/2b-it/2\"\n",
    "# MODEL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/13b-chat-hf/1\"\n",
    "\n",
    "# Found a good blog to catch me up fast!\n",
    "# https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "# https://huggingface.co/docs/transformers/v4.38.1/en/quantization#compute-data-type\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "# model = model.to_bettertransformer()\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdc537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:17.879370Z",
     "iopub.status.busy": "2024-03-11T15:55:17.878752Z",
     "iopub.status.idle": "2024-03-11T15:55:25.702101Z",
     "shell.execute_reply": "2024-03-11T15:55:25.701210Z"
    },
    "papermill": {
     "duration": 7.836698,
     "end_time": "2024-03-11T15:55:25.704438",
     "exception": false,
     "start_time": "2024-03-11T15:55:17.867740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"/kaggle/input/cot-1k-v0/checkpoint-200\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:25.724630Z",
     "iopub.status.busy": "2024-03-11T15:55:25.724295Z",
     "iopub.status.idle": "2024-03-11T15:55:26.987868Z",
     "shell.execute_reply": "2024-03-11T15:55:26.986918Z"
    },
    "papermill": {
     "duration": 1.276696,
     "end_time": "2024-03-11T15:55:26.990223",
     "exception": false,
     "start_time": "2024-03-11T15:55:25.713527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "TEST_DF_FILE = \"/kaggle/input/llm-prompt-recovery/test.csv\"\n",
    "SUB_DF_FILE = \"/kaggle/input/llm-prompt-recovery/sample_submission.csv\"\n",
    "NROWS = None if DEBUG else None\n",
    "\n",
    "if DEBUG:\n",
    "    TEST_DF_FILE = \"/kaggle/input/gemma-rewrite-nbroad/nbroad-v1.csv\"\n",
    "    SUB_DF_FILE = TEST_DF_FILE\n",
    "\n",
    "tdf = pd.read_csv(TEST_DF_FILE, nrows=NROWS, usecols=[\"id\", \"original_text\", \"rewritten_text\"])\n",
    "sub = pd.read_csv(SUB_DF_FILE, nrows=NROWS, usecols=[\"id\", \"rewrite_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e066ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:27.009364Z",
     "iopub.status.busy": "2024-03-11T15:55:27.009059Z",
     "iopub.status.idle": "2024-03-11T15:55:27.016928Z",
     "shell.execute_reply": "2024-03-11T15:55:27.016119Z"
    },
    "papermill": {
     "duration": 0.019692,
     "end_time": "2024-03-11T15:55:27.018857",
     "exception": false,
     "start_time": "2024-03-11T15:55:26.999165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples = pd.read_csv(\"/kaggle/input/gemini-dataset-3-8-k/gemini_dataset_v0.csv\")\n",
    "def truncate_txt(text, length):\n",
    "    text_list = text.split()\n",
    "    \n",
    "    if len(text_list) <= length:\n",
    "        return text\n",
    "    \n",
    "    return \" \".join(text_list[:length])\n",
    "\n",
    "USER_CHAT_TEMPLATE = \"\"\"<start_of_turn>user\\nYou'll be given an original text and a rewritten text generated by an LLM. \n",
    "Analyze the changes in the rewritten version and infer the likely prompt that led to those changes. \n",
    "Provide a detailed explanation of how you arrived at your inference step by step.\n",
    "\n",
    "**Original Text**:\n",
    "{}\n",
    "\n",
    "**Rewritten Text**\n",
    "{}\n",
    "\n",
    "You should response in the following format:\n",
    "**Inferred Promp**: ...\n",
    "\n",
    "**Chain of Thoughts**: ...<end_of_turn>\\n<start_of_turn>model\\n\"\"\"\n",
    "\n",
    "\n",
    "# USER_CHAT_TEMPLATE = \"\"\"<start_of_turn>user\\nYou'll be given an original text and a rewritten text generated by an LLM. \n",
    "# Analyze the stylistic changes in the rewritten version and identify the likely prompt that led to those changes. \n",
    "# Notice only output the prompt.\n",
    "# Here's what to focus on:\n",
    "# Shifts in Style: Look for changes in:\n",
    "# -Genre: (sci-fi, fantasy, historical fiction, etc.)\n",
    "# -Tone: (serious, humorous, conversational, etc.)\n",
    "# -Vocabulary: (formal vs. informal, technical vs. simple)\n",
    "# -Sentence Structure: (short and direct vs. flowing and complex)\n",
    "# Literary References: Consider if the rewritten style echoes a specific author or literary period (e.g., Shakespearean, Hemingway-esque).\n",
    "# Here is an example.\n",
    "# **Example Original Text**:\n",
    "# {}\n",
    "\n",
    "# **Example Rewritten Text**:\n",
    "# {}\n",
    "\n",
    "# **Example Output**:\n",
    "# {}\n",
    "\n",
    "# **Original Text**:\n",
    "# {}\n",
    "\n",
    "# **Rewritten Text**\n",
    "# {}\n",
    "# <end_of_turn>\\n<start_of_turn>model\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec96e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:27.037310Z",
     "iopub.status.busy": "2024-03-11T15:55:27.036998Z",
     "iopub.status.idle": "2024-03-11T15:55:27.043747Z",
     "shell.execute_reply": "2024-03-11T15:55:27.042979Z"
    },
    "papermill": {
     "duration": 0.01781,
     "end_time": "2024-03-11T15:55:27.045628",
     "exception": false,
     "start_time": "2024-03-11T15:55:27.027818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words_ids = 2\n",
    "from transformers.generation.stopping_criteria import StoppingCriteria, StoppingCriteriaList, STOPPING_CRITERIA_INPUTS_DOCSTRING, add_start_docstrings\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList()\n",
    "class StopAtSpecificTokenCriteria(StoppingCriteria):\n",
    "    \"\"\"\n",
    "    当生成出第一个指定token时，立即停止生成\n",
    "    ---------------\n",
    "    ver: 2023-08-02\n",
    "    by: changhongyu\n",
    "    \"\"\"\n",
    "    def __init__(self, token_id_list):\n",
    "        \"\"\"\n",
    "        :param token_id_list: 停止生成的指定token的id的列表\n",
    "        \"\"\"\n",
    "        self.token_id_list = token_id_list\n",
    "        \n",
    "    @add_start_docstrings(STOPPING_CRITERIA_INPUTS_DOCSTRING)\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # return np.argmax(scores[-1].detach().cpu().numpy()) in self.token_id_list\n",
    "        # 储存scores会额外占用资源，所以直接用input_ids进行判断\n",
    "        return input_ids[0][-1].detach().cpu().numpy() in self.token_id_list\n",
    "stopping_criteria.append(StopAtSpecificTokenCriteria(token_id_list=[108,109]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7805c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:27.064122Z",
     "iopub.status.busy": "2024-03-11T15:55:27.063861Z",
     "iopub.status.idle": "2024-03-11T15:55:55.937209Z",
     "shell.execute_reply": "2024-03-11T15:55:55.936465Z"
    },
    "papermill": {
     "duration": 28.885671,
     "end_time": "2024-03-11T15:55:55.939815",
     "exception": false,
     "start_time": "2024-03-11T15:55:27.054144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = accelerator.device\n",
    "tdf[\"id\"] = sub[\"id\"].copy()\n",
    "\n",
    "pbar = tqdm(total=tdf.shape[0])\n",
    "\n",
    "it = iter(tdf.iterrows())\n",
    "idx, row = next(it, (None, None))\n",
    "\n",
    "DEFAULT_TEXT = \"Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\n",
    "\n",
    "res = []\n",
    "\n",
    "while idx is not None:\n",
    "    \n",
    "    if (datetime.datetime.now() - start_time) > datetime.timedelta(hours=8, minutes=30):\n",
    "        res.append([row[\"id\"], DEFAULT_TEXT])\n",
    "        idx, row = next(it, (None, None))\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "        \n",
    "    try:\n",
    "#         random_idx = random.randint(0, len(examples) - 1)\n",
    "#         eot = truncate_txt(examples.loc[random_idx, \"original_text\"], 100)\n",
    "#         ert = truncate_txt(examples.loc[random_idx, \"rewritten_text\"], 100)\n",
    "#         e_ans = examples.loc[random_idx, \"rewrite_prompt\"]\n",
    "        prompt = USER_CHAT_TEMPLATE.format(truncate_txt(row[\"original_text\"], 400), truncate_txt(row[\"rewritten_text\"], 400))\n",
    "        prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\") \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_tokenized = lora_model.generate(**prompt_tokenized, max_new_tokens=50, use_cache=True, stopping_criteria=stopping_criteria)[0] \n",
    "        # remove prompt from output  \n",
    "        output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):] \n",
    "        decoded_output = tokenizer.decode(output_tokenized)\n",
    "#         res.append([row[\"id\"], decoded_output.split(\"<end_of_turn>\")[0]])\n",
    "        out =  decoded_output.split(\"**Inferred Prompt**:\")[1].split(\"\\n\")[0].strip()\n",
    "        if \"a\" <= out[-1] <= \"z\":\n",
    "            out = out + \".\"\n",
    "        res.append([row[\"id\"], out])\n",
    "                            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        res.append([row[\"id\"], DEFAULT_TEXT])\n",
    "        \n",
    "    finally:\n",
    "        idx, row = next(it, (None, None))\n",
    "        pbar.update(1)\n",
    "\n",
    "        \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de86c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:55.959752Z",
     "iopub.status.busy": "2024-03-11T15:55:55.959229Z",
     "iopub.status.idle": "2024-03-11T15:55:55.965922Z",
     "shell.execute_reply": "2024-03-11T15:55:55.965020Z"
    },
    "papermill": {
     "duration": 0.018743,
     "end_time": "2024-03-11T15:55:55.967745",
     "exception": false,
     "start_time": "2024-03-11T15:55:55.949002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3214a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:55.987498Z",
     "iopub.status.busy": "2024-03-11T15:55:55.987229Z",
     "iopub.status.idle": "2024-03-11T15:55:55.998857Z",
     "shell.execute_reply": "2024-03-11T15:55:55.997985Z"
    },
    "papermill": {
     "duration": 0.023641,
     "end_time": "2024-03-11T15:55:56.000842",
     "exception": false,
     "start_time": "2024-03-11T15:55:55.977201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(res, columns=[\"id\", \"rewrite_prompt\"])\n",
    "\n",
    "sub.to_csv(\"sample_submission.csv\", index=False)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430394d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T15:55:56.020331Z",
     "iopub.status.busy": "2024-03-11T15:55:56.020069Z",
     "iopub.status.idle": "2024-03-11T15:55:56.025398Z",
     "shell.execute_reply": "2024-03-11T15:55:56.024507Z"
    },
    "papermill": {
     "duration": 0.017334,
     "end_time": "2024-03-11T15:55:56.027463",
     "exception": false,
     "start_time": "2024-03-11T15:55:56.010129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a846832",
   "metadata": {
    "papermill": {
     "duration": 0.009205,
     "end_time": "2024-03-11T15:55:56.046135",
     "exception": false,
     "start_time": "2024-03-11T15:55:56.036930",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4481515,
     "sourceId": 7681339,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4506214,
     "sourceId": 7747717,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4538287,
     "sourceId": 7768887,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4538357,
     "sourceId": 7790371,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4576227,
     "sourceId": 7812664,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 164836055,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 165036286,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 3093,
     "sourceId": 4298,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3097,
     "sourceId": 4302,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 279.014728,
   "end_time": "2024-03-11T15:55:59.617504",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-11T15:51:20.602776",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0062b4a9aabe48949da0ae5696cf3415": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_edd49b27311145a19dd2e1d59c20202b",
       "placeholder": "​",
       "style": "IPY_MODEL_d6caa52a0d104d2fbf208f7472e6c026",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "37de26b866f44357a76898e011467136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "434a5c1e16004317a574609d2df212f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0062b4a9aabe48949da0ae5696cf3415",
        "IPY_MODEL_7c8be74fbfa942d6a8ec564a9867e596",
        "IPY_MODEL_8b90b660897446ef99ec8fe95ddfc1f7"
       ],
       "layout": "IPY_MODEL_b486f924f520427e858aedf22aa68246"
      }
     },
     "5157b9fe1a4c44ceaa67ebb79834759f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6348163009904f6496280cf5e37ccb95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c8be74fbfa942d6a8ec564a9867e596": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5157b9fe1a4c44ceaa67ebb79834759f",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_37de26b866f44357a76898e011467136",
       "value": 4
      }
     },
     "8b90b660897446ef99ec8fe95ddfc1f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6348163009904f6496280cf5e37ccb95",
       "placeholder": "​",
       "style": "IPY_MODEL_e0e8a5e515b54d83aef7edc821d3d9fe",
       "value": " 4/4 [02:16&lt;00:00, 30.96s/it]"
      }
     },
     "b486f924f520427e858aedf22aa68246": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6caa52a0d104d2fbf208f7472e6c026": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e0e8a5e515b54d83aef7edc821d3d9fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "edd49b27311145a19dd2e1d59c20202b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
